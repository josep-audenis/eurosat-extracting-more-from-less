{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ca9646b",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb72af94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.color import rgb2gray, rgb2hsv, rgb2lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998db879",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"../data/dataset/EuroSAT/\"\n",
    "categories = os.listdir(base_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a0318e",
   "metadata": {},
   "source": [
    "### Image composition\n",
    "\n",
    "First and foremost, it's important to visualize the images and know the dimensions of them. As we can see in the example below, the images are of size 64x64 pixels with 3 spectral bands. To the human eye the resolution is quite deceibing, but we can get a lot of information from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92c6d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = imread(base_path + \"Industrial/Industrial_1.jpg\")\n",
    "print(im.shape)\n",
    "imshow(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a993cd",
   "metadata": {},
   "source": [
    "We can also convert the original image to diferent color contexts, like grayscale, black & white, cielab or hsv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaca6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_gray = rgb2gray(im)\n",
    "imshow(im_gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3fff0a",
   "metadata": {},
   "source": [
    "A part from the visual point of view, we need to know how the data of the image is structured in the different color spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c1beac",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(im_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a2a798",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_bw = im_gray > 0.75\n",
    "imshow(im_bw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b53256",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(im_bw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276906c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(rgb2lab(im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8d98ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for cat in categories:\n",
    "\tfiles = os.listdir(base_path + cat)\n",
    "\timages.append(imread(base_path + cat + \"/\" + files[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f974506",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axs = plt.subplots(2, 5, figsize=(12, 5.5), layout=\"constrained\")\n",
    "axs = axs.flatten()\n",
    "for i, cat in enumerate(categories):\n",
    "\taxs[i].imshow(images[i])\n",
    "\taxs[i].set_title(cat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bf83e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axs = plt.subplots(2, 5, figsize=(12, 5.5), layout=\"constrained\")\n",
    "axs = axs.flatten()\n",
    "for i, cat in enumerate(categories):\n",
    "\taxs[i].imshow(rgb2gray(images[i]))\n",
    "\taxs[i].set_title(cat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55394dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axs = plt.subplots(2, 5, figsize=(12, 5.5), layout=\"constrained\")\n",
    "axs = axs.flatten()\n",
    "for i, cat in enumerate(categories):\n",
    "\taxs[i].imshow(rgb2gray(images[i]) > 0.75)\n",
    "\taxs[i].set_title(cat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefb49aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axs = plt.subplots(2, 5, figsize=(12, 5.5), layout=\"constrained\")\n",
    "axs = axs.flatten()\n",
    "for i, cat in enumerate(categories):\n",
    "\taxs[i].imshow(rgb2hsv(images[i]))\n",
    "\taxs[i].set_title(cat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc601f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axs = plt.subplots(2, 5, figsize=(12, 5.5), layout=\"constrained\")\n",
    "axs = axs.flatten()\n",
    "for i, cat in enumerate(categories):\n",
    "\t# axs[i].imshow((rgb2lab(images[i]) - rgb2lab(images[i]).min()) / (rgb2lab(images[i]).max() - rgb2lab(images[i]).min())) Normalized values for visualization (not accurate)\n",
    "\taxs[i].imshow(rgb2lab(images[i]))\n",
    "\taxs[i].set_title(cat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9cf28e",
   "metadata": {},
   "source": [
    "If we show an example of each category in all the diferent color spaces that we want to work with, we can start to see some differences that may indicate that some categories will be easier to classify than others, since the information of the image is quite different from the rest of the categories. But as we know, that's the job of the algorithm, here it's important to identify how and which features we can extract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d216df12",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axs = plt.subplots(10, 5, figsize=(13,25), layout=\"constrained\")\n",
    "axs = axs.flatten()\n",
    "\n",
    "for i, cat in enumerate(categories):\n",
    "\tfiles = os.listdir(base_path + \"/\" + cat)\n",
    "\timage = imread(base_path + \"/\" + cat + \"/\" + files[0])\n",
    "\t\n",
    "\taxs[i*5 + 0].imshow(image)\n",
    "\taxs[i*5 + 1].imshow(rgb2gray(image))\n",
    "\taxs[i*5 + 2].imshow(rgb2gray(image) > 0.75)\n",
    "\taxs[i*5 + 3].imshow(rgb2hsv(image))\n",
    "\taxs[i*5 + 4].imshow(rgb2lab(image))\n",
    "    \n",
    "\taxs[i*5 + 0].set_title(f\"{cat} (C)\")\n",
    "\taxs[i*5 + 1].set_title(f\"{cat} (G)\")\n",
    "\taxs[i*5 + 2].set_title(f\"{cat} (B/W)\")\n",
    "\taxs[i*5 + 3].set_title(f\"{cat} (HSV)\")\n",
    "\taxs[i*5 + 4].set_title(f\"{cat} (LAB)\")\n",
    "\t\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a2cf2b",
   "metadata": {},
   "source": [
    "As previously mentioned, the original images are in 3 spectral bands (RGB). A good representation of the color data is to use a histogram, this way we can visualize the color distribution and decide to apply different color features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff76db61",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axs = plt.subplots(10, 3, figsize=(8, 20), layout=\"constrained\")\n",
    "axs = axs.flatten()\n",
    "\n",
    "for i, cat in enumerate(categories):\n",
    "    files = os.listdir(base_path + \"/\" + cat)\n",
    "    image = imread(base_path + \"/\" + cat + \"/\" + files[0])\n",
    "    \n",
    "    r_vals = image[:, :, 0].flatten()\n",
    "    g_vals = image[:, :, 1].flatten()\n",
    "    b_vals = image[:, :, 2].flatten()\n",
    "    \n",
    "    r_ax = axs[i*3 + 0]  \n",
    "    g_ax = axs[i*3 + 1]  \n",
    "    b_ax = axs[i*3 + 2]  \n",
    "    \n",
    "    r_ax.hist(r_vals, bins=256, color='red')\n",
    "    g_ax.hist(g_vals, bins=256, color='green')\n",
    "    b_ax.hist(b_vals, bins=256, color='blue')\n",
    "    \n",
    "    r_ax.set_title(f\"{cat} (R)\")\n",
    "    g_ax.set_title(f\"{cat} (G)\")\n",
    "    b_ax.set_title(f\"{cat} (B)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71452d7",
   "metadata": {},
   "source": [
    "And to end up, it's essential to know how the dataset is distributed and populated. In this particular dataset, all categories have between 2000 and 3000 images, this important difference indicates that the dataset is not quite balanced. Maybe it would be interesting to take this into account when dealing with the train, test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef6a8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = []\n",
    "length = {}\n",
    "\n",
    "for cat in categories:\n",
    "\tfiles = os.listdir(base_path + cat + \"/\")\n",
    "\tprint(files)\n",
    "\tlength[cat] = len(files)\n",
    "\tfor image in files:\n",
    "\t\tim = imread(base_path + cat + \"/\" + image)\n",
    "\t\tshape = im.shape\n",
    "\t\tif shape not in sizes:\n",
    "\t\t\tsizes.append(shape)\n",
    "\n",
    "print(sizes)\n",
    "print(length)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
