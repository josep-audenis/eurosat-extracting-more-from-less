{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecdfa5ee",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "\n",
    "Given the previous analysis now we can address how we want to extract features from the data. The feature extraction will follow a pipeline divided by different feature categories:\n",
    "- Statistical Features\n",
    "- Texture Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcd477f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "\n",
    "from scipy.stats import entropy, skew, kurtosis\n",
    "from skimage.filters import laplace, gaussian, sobel, threshold_otsu, gabor\n",
    "from skimage.feature import canny, hog\n",
    "from skimage.feature import graycomatrix, graycoprops, local_binary_pattern\n",
    "from skimage.measure import shannon_entropy, moments_hu, moments, label, regionprops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af54446a",
   "metadata": {},
   "source": [
    "### Statistical Features\n",
    "\n",
    "Statistical moments from each RGB channel and combinations:\n",
    "- **First-order statistics:** mean, median, standard deviation, variance, sum, skewness, kurtosis\n",
    "- **Percentile features:** 10th, 25th, 75th, 90th percentiles\n",
    "- **Range and extrema:** min, max, range, interquartile range\n",
    "- **Entropy:** Shannon entropy\n",
    "\n",
    "With a total of **48 features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddb89d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def statisticalFeatures(image):\n",
    "\tfeatures = []\n",
    "\tfor channel in range(3):\n",
    "\t\tch_data = image[:, :, channel]\n",
    "\t\tfeatures += [\n",
    "\t\t\tnp.mean(ch_data),\n",
    "\t\t\tnp.median(ch_data),\n",
    "\t\t\tnp.std(ch_data),\n",
    "\t\t\tnp.var(ch_data),\n",
    "\t\t\tnp.sum(ch_data),\n",
    "\t\t\tskew(ch_data.flatten()),\n",
    "            kurtosis(ch_data.flatten()),\n",
    "\n",
    "\t\t\tnp.percentile(ch_data, 10),\n",
    "\t\t\tnp.percentile(ch_data, 25),\n",
    "\t\t\tnp.percentile(ch_data, 75),\n",
    "\t\t\tnp.percentile(ch_data, 90),\n",
    "\n",
    "\t\t\tnp.min(ch_data),\n",
    "\t\t\tnp.max(ch_data),\n",
    "\t\t\tnp.max(ch_data) - np.min(ch_data),\n",
    "\t\t\tnp.percentile(ch_data, 75) - np.percentile(ch_data, 25),\n",
    "\n",
    "\t\t\tshannon_entropy(ch_data)\n",
    "\t\t]\n",
    "\treturn features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5529d97c",
   "metadata": {},
   "source": [
    "### Texture Features\n",
    "\n",
    "Particularly powerful for land use classification:\n",
    "- **GLCM properties:** contrast, dissimilarity, homogeneity, ASM, energy, correlation\n",
    "\n",
    "With a total of **72 features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a8b77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def textureFeatures(image):\n",
    "\tfeatures = []\n",
    "\n",
    "\n",
    "\timage_gray = rgb2gray(image)\n",
    "\timage_gray = ((image_gray - image_gray.min()) / (image_gray.max() - image_gray.min()) * 255).astype(np.uint8)\t# Normalize to 0-255\n",
    "\n",
    "\n",
    "\n",
    "\tdistances = [1, 2, 3]\n",
    "\tangles = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
    "\n",
    "\tfor distance in distances:\n",
    "\t\tfor angle in angles:\n",
    "\t\t\t\n",
    "\t\t\tglcm = graycomatrix(image_gray, distances=[distance], angles=[angle], levels=256, symmetric=True, normed=True)\n",
    "\n",
    "\t\t\tfeatures += [\n",
    "\t\t\t\tgraycoprops(glcm, \"contrast\")[0, 0],\n",
    "\t\t\t\tgraycoprops(glcm, \"dissimilarity\")[0, 0],\n",
    "\t\t\t\t# graycoprops(glcm, \"homogeneity\")[0, 0],\n",
    "\t\t\t\t# graycoprops(glcm, \"ASM\")[0, 0],\n",
    "\t\t\t\t# graycoprops(glcm, \"energy\")[0, 0],\n",
    "\t\t\t\t# graycoprops(glcm, \"correlation\")[0, 0],\n",
    "\t\t\t]\n",
    "\n",
    "\treturn features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755432f2",
   "metadata": {},
   "source": [
    "### LBP Features\n",
    "\n",
    "- **Local Binary Pattern** histograms and statistics for each RGB channel\n",
    "\n",
    "With a total of **111 feautres**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4017d43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lbpFeatures(image):\n",
    "\n",
    "\tfeatures = []\n",
    "\n",
    "\tradius = 3\n",
    "\tn_points = 8 * radius\n",
    "\n",
    "\tfor channel in range(3):\n",
    "\n",
    "\t\tch_data = image[:, :, channel]\n",
    "\n",
    "\t\tlbp = local_binary_pattern(ch_data, n_points, radius, method=\"uniform\")\n",
    "\t\thist, _ = np.histogram(lbp.ravel(), bins=n_points + 2, range=(0, n_points + 2))\n",
    "\n",
    "\t\tfeatures.extend(hist)\n",
    "\n",
    "\t\tfeatures += [\n",
    "\t\t\tnp.mean(lbp),\n",
    "\t\t\tnp.std(lbp),\n",
    "\t\t\tnp.var(lbp)\n",
    "\t\t]\n",
    "\n",
    "\treturn features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f76fd8e",
   "metadata": {},
   "source": [
    "### Gabor Features\n",
    "\n",
    "- **Gabor filter** responses across diferent frequencies and orientations\n",
    "\n",
    "With a total of **216 features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6040f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaborFeatures(image):\n",
    "\tfeatures = []\n",
    "\n",
    "\tfrequencies = [0.1, 0.3, 0.5]\n",
    "\torientations = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
    "\n",
    "\tfor channel in range(3):\n",
    "\t\tchannel_data = image[:, :, channel]\n",
    "\n",
    "\t\tfor frequency in frequencies:\n",
    "\t\t\tfor theta in orientations:\n",
    "\n",
    "\t\t\t\treal, _ = gabor(channel_data, frequency=frequency, theta=theta)\n",
    "\n",
    "\t\t\t\tfeatures += [\n",
    "\t\t\t\t\tnp.mean(real),\n",
    "\t\t\t\t\tnp.std(real),\n",
    "\t\t\t\t\tnp.var(real),\n",
    "\t\t\t\t\tnp.max(real),\n",
    "\t\t\t\t\tnp.min(real),\n",
    "\t\t\t\t\tshannon_entropy(np.abs(real))\n",
    "\t\t\t\t]\n",
    "\n",
    "\treturn features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5422bdb4",
   "metadata": {},
   "source": [
    "### Color Space Feautres\n",
    "\n",
    "- Statistics from **HSV** and **LAB** color spaces\n",
    "\n",
    "With a total of **30 features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d95427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorSpaceFeatures(image):\n",
    "\n",
    "\tfeatures = []\n",
    "\n",
    "\thsv = rgb2hsv(image)\n",
    "\tlab = rgb2lab(image)\n",
    "\n",
    "\tfor channel in range(3):\n",
    "\t\thsv_channel_data = hsv[:, :, channel]\n",
    "\t\tlab_channel_data = lab[:, :, channel]\n",
    "\n",
    "\t\tfeatures += [\n",
    "\t\t\t# np.mean(hsv_channel_data),\n",
    "\t\t\tnp.mean(lab_channel_data),\n",
    "\t\t\t# np.std(hsv_channel_data),\n",
    "\t\t\tnp.std(lab_channel_data),\n",
    "\t\t\t# np.var(hsv_channel_data),\n",
    "\t\t\tnp.var(lab_channel_data),\n",
    "\t\t\tskew(hsv_channel_data.flatten()),\n",
    "\t\t\tskew(lab_channel_data.flatten()),\n",
    "\t\t\tkurtosis(hsv_channel_data.flatten()),\n",
    "\t\t\tkurtosis(lab_channel_data.flatten())\n",
    "\t\t]\n",
    "\n",
    "\treturn features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18876250",
   "metadata": {},
   "source": [
    "## Feature Pipeline\n",
    "\n",
    "Once all categorical feature extraction functions are designed, it's required to add them to a complete pipeline to merge all features in a single Data Frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ca7bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureExtraction(image):\n",
    "\tfeatures = []\n",
    "\n",
    "\tfeatures += statisticalFeatures(image)\n",
    "\tfeatures += textureFeatures(image)\n",
    "\tfeatures += lbpFeatures(image)\n",
    "\t# features += gaborFeatures(image)\n",
    "\tfeatures += colorSpaceFeatures(image)\n",
    "\n",
    "\n",
    "\treturn features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79714372",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = [] \n",
    "names = []\n",
    "\n",
    "max_per_cat = 10\n",
    "\n",
    "for cat in categories:\n",
    "\tprint(cat)\n",
    "\tfiles = os.listdir(base_path + cat + \"/\")\n",
    "\trandom.shuffle(files)\n",
    "\tfor i, image in enumerate(files):\n",
    "\t\tif i == max_per_cat:\n",
    "\t\t\tbreak\n",
    "\t\tpath = base_path + cat + \"/\" + image\n",
    "\t\tim = imread(path)\n",
    "\t\tdata.append(featureExtraction(im))\n",
    "\t\tlabels.append(cat)\n",
    "\t\tnames.append(image)\n",
    "\n",
    "X = np.array(data).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3750313e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbe93f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X)\n",
    "\n",
    "x = X\n",
    "y = labels\n",
    "image_paths = names\n",
    "df[\"class\"] = labels\n",
    "df[\"name\"] = names\n",
    "df\n",
    "print(df.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3c6d95",
   "metadata": {},
   "source": [
    "## ML Models\n",
    "\n",
    "Once the Data Frame has been created with all the extracted features, we can use this data to train the classical ML models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339b1047",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_curve, roc_auc_score, auc\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, label_binarize\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca28229",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(columns = [\"class\", \"name\"])\n",
    "y = df[\"class\"]\n",
    "image_paths = df[\"name\"]\n",
    "target_names = y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52951d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.25, stratify=y)\n",
    "feature_columns = x_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83872ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_train, y_train)\n",
    "y_pred = rf.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bf7c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "sns.heatmap(confusion_matrix(y_test,y_pred),annot=True, xticklabels=target_names, yticklabels=target_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
